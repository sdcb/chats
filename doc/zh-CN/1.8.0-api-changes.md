# Chats 1.8.0 后端 API 接口变更说明

> 本文档详细说明了 1.8.0 版本中所有后端 API 接口的变更，以指导前端进行相应的适配工作。

## 概述

1.8.0 版本的核心变更是**将模型能力配置从 `ModelReference` 表迁移到 `Model` 表**，使每个模型实例都拥有独立的完整配置。这一架构调整影响了多个管理接口的请求/响应格式。

### 主要影响

- **模型管理接口**：删除了 3 个 `ModelReference` 相关字段，新增了 18 个配置字段（全部必填，后端保证返回）
- **模型验证接口**：请求参数从简单的 `ModelReferenceId` 改为完整的 `UpdateModelRequest`
- **可用模型列表接口**：移除了 3 个与 `ModelReference` 相关的字段
- **快速创建接口**：`POST /api/admin/models/fast-create` 已删除，请使用普通创建接口 `POST /api/admin/models`，并提供合理的默认值

---

## 1. 模型管理接口变更

### 1.1 获取模型详情 - `GET /api/admin/models/{id}`

#### 响应格式变更

**删除 3 个字段**：

```typescript
// ❌ 已删除的字段（不再依赖 ModelReference 表）
modelReferenceId: number;
modelReferenceName: string;
modelReferenceShortName: string | null;
```

**新增 18 个字段**（全部必填）：

```typescript
interface AdminModelDto {
  // ... 原有字段 ...
  
  // === 新增字段 ===
  
  // 功能开关字段 (boolean 类型)
  allowSearch: boolean;              // 是否支持联网搜索
  allowVision: boolean;              // 是否支持视觉理解
  allowSystemPrompt: boolean;        // 是否支持系统提示词
  allowStreaming: boolean;           // 是否支持流式输出
  allowCodeExecution: boolean;       // 是否支持代码执行
  allowToolCall: boolean;            // 是否支持工具调用
  thinkTagParserEnabled: boolean;    // 是否启用思考标签解析
  
  // 温度范围字段 (number 类型, 0-2)
  minTemperature: number;            // 最小温度值
  maxTemperature: number;            // 最大温度值
  
  // Token 配置字段 (number 类型)
  contextWindow: number;             // 上下文窗口大小
  maxResponseTokens: number;         // 最大响应 Token 数
  
  // 推理级别选项 (number[] 类型)
  reasoningEffortOptions: number[];  // 可选推理级别 [0=Default, 1=Minimal, 2=Low, 3=Medium, 4=High]
  
  // 图像尺寸支持 (string[] 类型)
  supportedImageSizes: string[];     // 支持的图像尺寸，如 ["1024x1024", "1792x1024", "1024x1792"]
  
  // API 类型字段
  apiType: number;                   // API 类型 [0=ChatCompletion, 1=Response]
  useAsyncApi: boolean;              // 是否使用异步 API (如 o3-pro)
  
  // Token 字段命名
  useMaxCompletionTokens: boolean;   // 是否使用 max_completion_tokens 字段 (OpenAI/Azure)
  
  // 遗留标记
  isLegacy: boolean;                 // 是否为遗留模型 (2024-07-01 之前)
}
```

#### 字段说明

##### 功能开关字段

| 字段 | 类型 | 说明 | 数据来源（迁移时） |
|------|------|------|--------|
| `allowSearch` | `boolean` | 模型是否支持联网搜索功能 | 从 ModelReference 迁移 |
| `allowVision` | `boolean` | 模型是否支持图像理解能力 | 从 ModelReference 迁移 |
| `allowSystemPrompt` | `boolean` | 模型是否支持系统提示词 | 从 ModelReference 迁移 |
| `allowStreaming` | `boolean` | 模型是否支持流式响应<br>**字段复用**：<br>• `apiType=0/1`：流式文本输出<br>• `apiType=2`：返回中间状态预览图片 | 从 ModelReference 迁移 |
| `allowCodeExecution` | `boolean` | 模型是否支持代码执行 (Gemini) | 根据模型名称自动判断 |
| `allowToolCall` | `boolean` | 模型是否支持工具调用 | 从 ModelReference 迁移 |
| `thinkTagParserEnabled` | `boolean` | 是否启用 `<think>` 标签解析 (DeepSeek) | 根据模型名称自动判断 |

##### 温度范围字段

| 字段 | 类型 | 说明 | 取值范围 |
|------|------|------|----------|
| `minTemperature` | `number` | 最小温度值 | 0.0 - 2.0 |
| `maxTemperature` | `number` | 最大温度值 | 0.0 - 2.0 |

**注意**：温度值按原值存储（0-2 范围），使用时会通过 `ClampTemperature` 方法将实际温度限制在此范围内。

##### Token 配置字段

| 字段 | 类型 | 说明 |
|------|------|------|
| `contextWindow` | `number` | 模型的上下文窗口大小（输入 Token 限制） |
| `maxResponseTokens` | `number` | **字段复用**：<br>• `apiType=0/1`：最大响应 Token 数（输出 Token 限制）<br>• `apiType=2`：最大批量生成图片数 |

**注意**：`maxResponseTokens` 在图像生成模型中表示一次请求最多可以生成的图片数量，而不是 Token 数。

##### 推理级别字段

| 字段 | 类型 | 说明 | 枚举值 |
|------|------|------|--------|
| `reasoningEffortOptions` | `number[]` | **字段复用**：<br>• `apiType=0/1`：支持的推理级别选项<br>• `apiType=2`：支持的图片生成质量选项 | `0`=Default（默认）<br>`1`=Minimal（最小）<br>`2`=Low（低/低质量）<br>`3`=Medium（中/中等质量）<br>`4`=High（高/高质量） |

**说明**：
- **Chat/Response 模型** (`apiType=0/1`)：表示推理强度，用于控制模型思考深度
  - `[2, 3, 4]` - 支持 Low、Medium、High 三个级别（传统推理模型，如 o1/o3）
  - `[1, 2, 3, 4]` - 支持 Minimal、Low、Medium、High 四个级别（gpt-5 系列）
  - `[2]` - 仅支持 Low 级别（兼容模式，如某些 Gemini/Qwen 模型）
  - `[]` 或 `[0]` - 不支持推理级别或使用默认值
- **ImageGeneration 模型** (`apiType=2`)：表示图片生成质量
  - `[2, 3, 4]` - 支持低、中、高三种质量（标准配置）
  - 映射关系：2=Low→"low"质量，3=Medium→"medium"质量，4=High→"high"质量
  - `[]` 或 `[0]` - 使用默认质量

##### 图像尺寸字段

| 字段 | 类型 | 说明 | 示例值 |
|------|------|------|--------|
| `supportedImageSizes` | `string[]` | 支持的图像尺寸列表 | `["1024x1024", "1792x1024", "1024x1792"]` |

##### API 类型字段

| 字段 | 类型 | 说明 | 枚举值 |
|------|------|------|--------|
| `apiType` | `number` | API 类型 | `0` = ChatCompletion API（默认，聊天对话）<br>`1` = Response API（推理模型，如 o1/o3 系列）<br>`2` = ImageGeneration API（图像生成，如 DALL-E） |
| `useAsyncApi` | `boolean` | 是否使用异步 API | `true` = 异步模式（需轮询结果，如 o3-pro）<br>`false` = 同步模式（默认） |

**说明**：
- **聊天模型**（如 GPT-4、Claude）：`apiType=0`
- **推理模型**（如 o1、o3、gpt-5 系列）：`apiType=1`，o3-pro 额外设置 `useAsyncApi=true`
- **图像生成模型**（如 DALL-E、gpt-image-1）：`apiType=2`

##### Token 字段命名

| 字段 | 类型 | 说明 |
|------|------|------|
| `useMaxCompletionTokens` | `boolean` | 控制 Token 限制字段名称<br>`true` = 使用 `max_completion_tokens`（OpenAI/Azure）<br>`false` = 使用 `max_tokens`（其他提供商） |

**说明**: OpenAI 和 Azure OpenAI 使用 `max_completion_tokens` 字段来限制响应 Token 数,而其他提供商（如 DeepSeek 等）使用 `max_tokens` 字段表示最大响应 Token 数。

##### 遗留标记

| 字段 | 类型 | 说明 |
|------|------|------|
| `isLegacy` | `boolean` | 标记模型是否为遗留模型（如 gpt-3.5-turbo 等早期模型），用于前端显示"过期"标记 |

---

### 1.2 创建/更新模型 - `POST /api/admin/models` 和 `PUT /api/admin/models/{id}`

#### 请求格式变更

**新增 18 个字段**（全部必填）：

```typescript
interface UpdateModelRequest {
  // ... 原有字段 ...
  
  // === 新增字段（与 AdminModelDto 相同，全部必填）===
  allowSearch: boolean;
  allowVision: boolean;
  allowSystemPrompt: boolean;
  allowStreaming: boolean;
  allowCodeExecution: boolean;
  allowToolCall: boolean;
  thinkTagParserEnabled: boolean;
  
  minTemperature: number;
  maxTemperature: number;
  
  contextWindow: number;
  maxResponseTokens: number;
  
  reasoningEffortOptions: number[];
  supportedImageSizes: string[];
  
  apiType: number;
  useAsyncApi: boolean;
  useMaxCompletionTokens: boolean;
  isLegacy: boolean;
}
```

#### 前端适配要点

1. **表单字段分组**：模型编辑表单按以下顺序组织字段

   **基础信息**（所有模型都需要）：
   - 模型显示名称 (`name`)
   - 密钥 (`modelKeyId`)
   - 部署名称 (`deploymentName`)
   - 价格 (`inputTokenPrice1M`, `outputTokenPrice1M`)
   - 遗留标记 (`isLegacy`)

   **通用配置**（ChatCompletion 和 Response 共享）：
   - 功能开关：`allowVision`, `allowSearch`, `allowSystemPrompt`, `allowStreaming`, `allowCodeExecution`, `allowToolCall`, `thinkTagParserEnabled`
   - 温度范围：`minTemperature`, `maxTemperature`
   - Token 配置：`contextWindow`, `maxResponseTokens`
   - 推理级别：`reasoningEffortOptions`
   - Token 字段命名：`useMaxCompletionTokens`

   **API 类型选择**：
   - `apiType` 下拉框：
     - `0` - ChatCompletion（聊天对话）
     - `1` - Response（推理模型）
     - `2` - ImageGeneration（图像生成）

   **API 类型相关配置**（根据 `apiType` 显示）：
   - 仅 `apiType=1` (Response) 显示：
     - `useAsyncApi`（是否使用异步 API）
   - 仅 `apiType=2` (ImageGeneration) 显示：
     - `allowStreaming`（是否返回中间状态预览图片）
     - `supportedImageSizes`（支持的图像尺寸）
     - `maxResponseTokens`（显示为"最大批量生成图片数"，字段复用）

   **注意 - 字段复用**：
   - **`allowStreaming`** 在不同 API 类型下有不同含义：
     - `apiType=0/1`：流式文本输出
     - `apiType=2`：返回中间状态预览图片
   - **`maxResponseTokens`** 在不同 API 类型下有不同含义：
     - `apiType=0/1`：最大响应 Token 数
     - `apiType=2`：最大一次性批量输出的图片数量
   - **`reasoningEffortOptions`** 在不同 API 类型下有不同含义：
     - `apiType=0/1`：推理强度选项（2=Low, 3=Medium, 4=High，用于控制思考深度）
     - `apiType=2`：图片生成质量选项（2=Low, 3=Medium, 4=High，用于控制图片质量）

2. **条件显示逻辑**：
   ```typescript
   // 伪代码示例
   const showGeneralConfig = apiType === 0 || apiType === 1; // ChatCompletion 或 Response
   const showUseAsyncApi = apiType === 1; // 仅 Response
   const showImageSizes = apiType === 2; // 仅 ImageGeneration
   const showMaxResponseTokens = true; // 所有类型都需要，但显示标签不同
   const showReasoningEffortOptions = true; // 所有类型都可能需要，但显示标签不同
   const showAllowStreaming = true; // 所有类型都需要，但含义不同
   
   // 显示标签根据 apiType 调整
   const maxResponseTokensLabel = apiType === 2 
     ? "最大批量生成图片数" 
     : "最大响应 Token 数";
   
   const reasoningEffortOptionsLabel = apiType === 2
     ? "图片生成质量选项"
     : "推理强度选项";
   
   const allowStreamingLabel = apiType === 2
     ? "返回中间状态预览图片"
     : "支持流式输出";
   ```

3. **验证规则**：
   - `minTemperature` 和 `maxTemperature` 范围：0.0 - 2.0
   - `minTemperature` <= `maxTemperature`
   - `reasoningEffortOptions` 值范围：0-4（0=Default, 1=Minimal, 2=Low, 3=Medium, 4=High）
     - 对于 `apiType=2` (ImageGeneration)，通常使用 2/3/4（低/中/高质量）
   - `apiType` 值范围：0-2（0=ChatCompletion, 1=Response, 2=ImageGeneration）

4. **创建模型时的默认值建议**（常规通用值，管理员可后续在编辑对话框中调整）：
   - **基础信息**：
     - `name`: 使用 `deploymentName`
     - `enabled: true`
     - `inputTokenPrice1M: 0`
     - `outputTokenPrice1M: 0`
     - `isLegacy: false`
   - **通用配置**（`apiType=0` 或 `1` 时适用）：
     - `allowVision: false`
     - `allowSearch: false`
     - `allowSystemPrompt: true`
     - `allowStreaming: true`
     - `allowCodeExecution: false`
     - `allowToolCall: true`
     - `thinkTagParserEnabled: false`
     - `minTemperature: 0.0`
     - `maxTemperature: 2.0`
     - `contextWindow: 128000`
     - `maxResponseTokens: 4096`（对话/推理模型）
     - `reasoningEffortOptions: []`（空数组）
     - `useMaxCompletionTokens: false`
   - **API 类型**：`apiType: 0`（默认为聊天对话）
   - **Response 特有**（`apiType=1` 时）：`useAsyncApi: false`
   - **ImageGeneration 特有**（`apiType=2` 时）：
     - `supportedImageSizes: []`（空数组）
     - `maxResponseTokens: 1`（默认一次生成 1 张图片）

#### 从可用模型列表快速创建

在"可用模型列表"（`GET /api/admin/model-keys/{modelKeyId}/possible-models`）中，前端可以为未添加的模型（`isExists=false`）提供"快速添加"按钮：

```typescript
async function quickCreateModel(deploymentName: string, modelKeyId: number) {
  // 使用通用的默认配置(不做智能推断,管理员可后续调整)
  const defaultConfig = {
    name: deploymentName,
    deploymentName: deploymentName,
    modelKeyId: modelKeyId,
    enabled: true,
    
    // 功能开关 - 使用保守的默认值
    allowVision: false,
    allowSearch: false,
    allowSystemPrompt: true,
    allowStreaming: true,
    allowCodeExecution: false,
    allowToolCall: true,
    thinkTagParserEnabled: false,
    
    // 温度范围
    minTemperature: 0.0,
    maxTemperature: 2.0,
    
    // Token 配置
    contextWindow: 128000,
    maxResponseTokens: 4096,
    
    // 推理级别 - 空数组表示不支持
    reasoningEffortOptions: [],
    
    // 图像尺寸 - 空数组表示不支持
    supportedImageSizes: [],
    
    // API 类型 - 默认 ChatCompletion API
    apiType: 0,
    useAsyncApi: false,
    
    // Token 字段命名 - 默认使用 max_tokens
    useMaxCompletionTokens: false,
    
    // 价格(默认值,管理员可后续调整)
    inputTokenPrice1M: 0,
    outputTokenPrice1M: 0,
    
    isLegacy: false,
  };
  
  const response = await fetch('/api/admin/models', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(defaultConfig)
  });
  
  if (!response.ok) {
    throw new Error('Failed to create model');
  }
  
  return await response.json();
}
```

**说明**:
- 使用普通的 `POST /api/admin/models` 接口创建模型(不再使用已删除的 `fast-create` 接口)
- 使用通用的保守默认值,不做智能推断
- 管理员可以在创建后通过编辑对话框调整配置(如启用 vision、设置推理级别等)

---

## 2. 模型验证接口变更

### 2.1 验证模型 - `POST /api/admin/models/validate`

#### ⚠️ 破坏性变更

接口参数从简单的 `ModelReferenceId` 改为完整的模型配置对象。

#### 请求格式变更

**之前（1.7.x）**：
```typescript
interface ValidateModelRequest {
  modelReferenceId: number;  // 只需传模型引用 ID
}
```

**现在（1.8.0）**：
```typescript
interface UpdateModelRequest {
  // 所有字段必填
  name: string;
  enabled: boolean;
  modelKeyId: number;
  deploymentName: string;
  
  allowSearch: boolean;
  allowVision: boolean;
  allowSystemPrompt: boolean;
  allowStreaming: boolean;
  allowCodeExecution: boolean;
  allowToolCall: boolean;
  thinkTagParserEnabled: boolean;
  
  minTemperature: number;
  maxTemperature: number;
  
  contextWindow: number;
  maxResponseTokens: number;
  
  reasoningEffortOptions: number[];
  supportedImageSizes: string[];
  
  apiType: number;
  useAsyncApi: boolean;
  useMaxCompletionTokens: boolean;
  isLegacy: boolean;
}
```

#### 响应格式（无变更）

```typescript
interface ValidateModelResponse {
  success: boolean;
  message?: string;  // 错误信息（如果验证失败）
}
```

#### 验证逻辑说明

后端会：
1. 创建一个临时的 `Model` 对象（不保存到数据库）
2. 使用传入的配置初始化模型加载器
3. 发送测试请求："1+1=?"
4. 如果模型支持推理级别，则使用 `Medium` 级别进行测试
5. 返回验证结果

#### 前端适配要点

1. **参数构造**：将完整的模型配置对象传给验证接口
2. **表单集成**：在模型编辑表单中，"验证"按钮应传递当前表单的所有值
3. **错误处理**：显示详细的验证错误信息（如 API 密钥无效、模型不存在等）

#### 迁移示例

**之前的代码**：
```typescript
async function validateModel(modelReferenceId: number) {
  const response = await fetch('/api/admin/models/validate', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ modelReferenceId })
  });
  return await response.json();
}
```

**迁移后的代码**：
```typescript
async function validateModel(modelConfig: UpdateModelRequest) {
  const response = await fetch('/api/admin/models/validate', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(modelConfig)  // 传递完整配置
  });
  return await response.json();
}

// 调用示例
const formData = {
  modelKeyId: 1,
  deploymentName: 'gpt-4',
  allowStreaming: true,
  useMaxCompletionTokens: true,
  // ... 其他配置
};
await validateModel(formData);
```

---

## 3. 可用模型列表接口变更

### 3.1 获取 ModelKey 的可用模型 - `GET /api/admin/model-keys/{modelKeyId}/possible-models`

#### 响应格式变更

**移除 3 个字段**：

```typescript
// 之前（1.7.x）
interface PossibleModelDto {
  referenceName: string;      // ❌ 已移除
  modelReferenceId: number;   // ❌ 已移除
  isLegacy: boolean;          // ❌ 已移除
  deploymentName: string | null;
  isExists: boolean;
}

// 现在（1.8.0）
interface PossibleModelDto {
  deploymentName: string;     // ✅ 改为必填（string）
  isExists: boolean;          // ✅ 保留
}
```

#### 字段说明

| 字段 | 类型 | 说明 |
|------|------|------|
| `deploymentName` | `string` | 模型的部署名称（从 loader 获取的原始模型名） |
| `isExists` | `boolean` | 该模型是否已添加到当前 ModelKey |

#### 后端行为变更

- **之前**：查询 `ModelReference` 表获取可用模型列表
- **现在**：直接调用各提供商的 `ModelLoader.ListModels()` 获取实时模型列表
- **不支持的提供商**：如果 ModelProvider 不支持 loader，会抛出异常

#### 前端适配要点

1. **移除字段引用**：删除所有对 `referenceName`、`modelReferenceId`、`isLegacy` 的引用
2. **仅使用 `deploymentName`**：作为模型的唯一标识符
3. **错误处理**：捕获提供商不支持 loader 的异常
4. **类型更新**：`deploymentName` 从 `string | null` 改为 `string`（非空）

#### 迁移示例

**之前的代码**：
```typescript
interface PossibleModel {
  referenceName: string;
  modelReferenceId: number;
  deploymentName: string | null;
  isExists: boolean;
  isLegacy: boolean;
}

function renderModelList(models: PossibleModel[]) {
  return models.map(model => (
    <div key={model.modelReferenceId}>
      <span>{model.referenceName}</span>
      {model.isLegacy && <Badge>遗留</Badge>}
      <span>{model.deploymentName || '未部署'}</span>
    </div>
  ));
}
```

**迁移后的代码**：
```typescript
interface PossibleModel {
  deploymentName: string;  // 非空
  isExists: boolean;
}

function renderModelList(models: PossibleModel[]) {
  return models.map(model => (
    <div key={model.deploymentName}>  {/* 使用 deploymentName 作为 key */}
      <span>{model.deploymentName}</span>
      {!model.isExists && (
        <Button onClick={() => quickCreateModel(model.deploymentName, modelKeyId)}>
          添加
        </Button>
      )}
    </div>
  ));
}
```

---

## 4. 用户侧模型接口变更

### 4.1 用户模型列表 - `GET /api/users/{userId}/models`

#### 响应格式变更

每个模型对象新增以下字段（全部必填）：

```typescript
interface UserModelDto {
  // ... 原有字段 ...
  
  // === 新增字段（与 AdminModelDto 相同）===
  allowVision: boolean;              // 是否支持视觉
  allowSearch: boolean;              // 是否支持搜索
  allowSystemPrompt: boolean;        // 是否支持系统提示词
  allowStreaming: boolean;           // 是否支持流式输出
  thinkTagParserEnabled: boolean;    // 是否启用思考标签解析
  
  minTemperature: number;            // 最小温度
  maxTemperature: number;            // 最大温度
  
  contextWindow: number;             // 上下文窗口
  maxResponseTokens: number;         // 最大响应 Token 数
  
  allowCodeExecution: boolean;       // 是否支持代码执行
  reasoningEffortOptions: number[];  // 推理级别选项
  allowToolCall: boolean;            // 是否支持工具调用
  supportedImageSizes: string[];     // 支持的图像尺寸
  
  apiType: number;                   // API 类型
  useAsyncApi: boolean;              // 是否使用异步 API
  useMaxCompletionTokens: boolean;   // 是否使用 max_completion_tokens
  isLegacy: boolean;                 // 是否为遗留模型
}
```

**注意**：用户侧接口返回完整的 `AdminModelDto`，包含所有管理字段。前端可根据需要选择性显示。

#### 前端适配要点

1. **UI 显示**：根据新字段在用户界面显示模型能力（所有字段都有明确值，无需判空）
2. **功能控制**：
   - 根据 `apiType` 显示不同的交互界面：
     - `apiType=0` (ChatCompletion): 显示聊天对话界面
     - `apiType=1` (Response): 显示推理模型界面（可能需要等待时间提示）
     - `apiType=2` (ImageGeneration): 显示图像生成界面
   - 根据 `allowVision` 显示/隐藏图像上传功能
   - 根据 `allowSearch` 显示/隐藏联网搜索开关
   - 根据 `allowCodeExecution` 显示代码执行相关 UI
3. **参数限制**：
   - 温度滑块范围：`minTemperature` 到 `maxTemperature`（仅 `apiType=0` 或 `1` 需要）
   - 推理级别下拉框：根据 `reasoningEffortOptions` 生成选项（仅 `apiType=1` 需要，空数组表示不支持）
   - 图像尺寸选择器：根据 `supportedImageSizes` 提供尺寸选项（仅 `apiType=2` 需要，空数组表示不支持）
   - 图片数量选择：根据 `maxResponseTokens` 提供数量选项（仅 `apiType=2` 需要，表示最大批量生成图片数）
4. **模型类型判断**：
   - 使用 `apiType` 字段判断模型类型，而不是 `supportedImageSizes` 或其他字段
   - `apiType` 是模型类型的权威标识
5. **字段复用注意**：
   - `maxResponseTokens` 在 `apiType=2` 时表示"最大批量生成图片数"，而不是 Token 数

---

## 5. 其他接口变更

### 5.1 公共模型列表 - `GET /api/public/models`

响应格式与用户侧模型列表相同（参见 4.1）。

---

## 6. 数据迁移说明

### 6.1 数据库迁移脚本

**文件路径**：`db-migration/1.8/1.8.0.sql`

**主要步骤**：

1. **添加字段**：为 `Model` 表添加 18 个新字段
2. **迁移数据**：从 `ModelReference` 表迁移能力配置到 `Model` 表
3. **特殊处理**：
   - 根据模型名称自动设置 `AllowCodeExecution`（Gemini 模型）
   - 根据模型名称自动设置 `ThinkTagParserEnabled`（DeepSeek 模型）
   - 根据模型名称自动设置推理级别选项（o1/o3 系列）
   - 根据模型名称自动设置图像尺寸（DALL-E/图像生成模型）
   - 为 o3-pro 设置 `UseAsyncApi=1` 和 `ApiType=1`
   - 为 OpenAI/Azure OpenAI 设置 `UseMaxCompletionTokens=1`
   - 根据发布日期设置 `IsLegacy`
4. **设置非空**：将 `DeploymentName` 改为 NOT NULL
5. **删除外键**：删除 `ModelReferenceId` 外键和列

### 6.2 前端迁移检查清单

升级到 1.8.0 之前，请确认前端已完成以下适配：

- [ ] 更新 `AdminModelDto` 类型定义（删除 3 个 ModelReference 字段，新增 18 个配置字段，全部必填）
- [ ] 更新 `UpdateModelRequest` 类型定义（新增 18 个字段，全部必填）
- [ ] 更新 `PossibleModelDto` 类型定义（移除 3 个字段）
- [ ] 移除所有对 `modelReferenceId`、`modelReferenceName`、`modelReferenceShortName` 的引用
- [ ] 用户侧模型接口使用 `AdminModelDto`（包含所有字段）
- [ ] 重构"验证模型"功能，传递完整配置对象
- [ ] 实现快速创建模型功能（使用通用默认值，不做智能推断）
- [ ] 更新模型编辑表单（新增 18 个输入控件）
- [ ] 更新用户界面的模型能力显示（无需判空，所有字段都有值）
- [ ] 移除所有对 `ModelReference` 相关字段的引用
- [ ] 移除对 `fast-create` 接口的调用(改用普通创建接口)
- [ ] 测试所有模型管理流程

---

## 7. 常见问题

### Q1: 为什么要移除 `ModelReference`？

**A**: 1.8.0 之前，模型配置分散在两个表中：
- `ModelReference`：存储模型的通用能力配置（如支持 vision、温度范围等）
- `Model`：存储特定实例的配置（如 API 密钥、部署名称等）

这导致：
- 无法为同一模型引用的不同实例定制配置
- 增加了代码复杂度（需要同时查询两个表）
- 限制了灵活性

1.8.0 将所有配置合并到 `Model` 表，每个模型实例都是独立的，可以单独定制配置。前端不再需要 `modelReferenceId`、`modelReferenceName`、`modelReferenceShortName` 这些字段。

### Q2: 前端如何适配删除的 3 个字段？

**A**: 这 3 个字段完全删除，前端应：
1. **删除字段引用**：移除所有对 `modelReferenceId`、`modelReferenceName`、`modelReferenceShortName` 的引用
2. **使用新字段**：改为直接使用模型的 18 个新配置字段（如 `allowVision`、`contextWindow` 等）
3. **显示名称**：使用 `name` 或 `deploymentName` 显示模型名称，不再使用 `modelReferenceName`
4. **模型能力**：直接读取模型自身的能力字段，不再通过 `modelReferenceId` 关联查询

### Q3: `isLegacy` 字段的作用是什么？

**A**: 标记模型是否为"遗留模型"（如 gpt-3.5-turbo 等早期模型）。这些模型虽然仍可用,但已不再是主流选择,用户通常不再关心。前端可以使用此字段显示"过期"或"遗留"标记,提示用户考虑使用更新的模型。

**注意**: 此字段与 API 兼容性无关,仅用于标识模型的时代性。

### Q4: `useMaxCompletionTokens` 字段的作用是什么？

**A**: 控制限制响应 Token 数时使用的字段名称:
- **OpenAI/Azure OpenAI**: 使用 `max_completion_tokens` 字段
- **其他提供商**: 使用 `max_tokens` 字段表示最大响应 Token 数（如 DeepSeek 等）

这是不同提供商的 API 设计差异,与模型是否过期无关。

### Q5: `apiType` 和 `useAsyncApi` 的区别？

**A**:
- `apiType`: 区分 API 端点类型
  - `0` (ChatCompletion): 标准聊天对话 API（同步或流式），如 GPT-4、Claude、Gemini 等
  - `1` (Response): 推理模型 API，如 o1、o3、gpt-5 系列等
  - `2` (ImageGeneration): 图像生成 API，如 DALL-E、gpt-image-1 等
- `useAsyncApi`: 区分调用模式（仅对 Response API 有意义）
  - `false`: 同步调用，等待响应返回（大部分推理模型）
  - `true`: 异步调用，需要轮询结果（如 o3-pro）

**示例**：
- 普通 GPT-4: `apiType=0, useAsyncApi=false`
- o1-preview: `apiType=1, useAsyncApi=false`
- o3-pro: `apiType=1, useAsyncApi=true`
- DALL-E: `apiType=2, useAsyncApi=false`

### Q6: 前端如何处理不支持 loader 的提供商？

**A**: 当调用 `GET /api/admin/model-keys/{modelKeyId}/possible-models` 时，如果该提供商不支持 loader，后端会返回错误响应。前端应：
1. 捕获错误并显示友好提示："该提供商暂不支持自动获取模型列表，请手动添加模型"
2. 提供"手动添加模型"的入口，直接跳转到模型创建表单

### Q7: 字段复用是什么意思？

**A**: 为了减少数据库字段数量，部分字段在不同 `apiType` 下有不同的含义和用途：

1. **`maxResponseTokens`**：
   - `apiType=0/1` (Chat/Response)：最大响应 Token 数（输出 Token 限制）
   - `apiType=2` (ImageGeneration)：最大批量生成图片数（一次请求最多生成多少张图片）

2. **`reasoningEffortOptions`**：
   - `apiType=0/1` (Chat/Response)：推理强度选项（控制模型思考深度）
     - 示例：`[2, 3, 4]` 表示支持 Low/Medium/High 推理级别
   - `apiType=2` (ImageGeneration)：图片生成质量选项（控制图片质量）
     - 示例：`[2, 3, 4]` 表示支持低/中/高三种质量
     - 映射关系：2→"low"质量，3→"medium"质量，4→"high"质量

**前端注意事项**：
- 字段名称保持不变，但显示标签应根据 `apiType` 动态调整
- 验证规则和枚举值保持一致（0-4）
- 后端会根据 `apiType` 自动使用正确的映射逻辑

### Q7: 温度值的处理逻辑是什么？
1. 捕获错误并显示友好提示："该提供商暂不支持自动获取模型列表，请手动添加模型"
2. 提供"手动添加模型"的入口，直接跳转到模型创建表单

### Q7: 温度值的处理逻辑是什么？

**A**: 温度值的处理逻辑：
- **存储**：按用户输入的原值存储（通常 0-2 范围），不做转换
- **使用**：在实际调用 AI 服务时，通过 `ClampTemperature` 方法将温度值限制在 `minTemperature` 和 `maxTemperature` 之间
- **验证**：前端应确保 `minTemperature` <= `maxTemperature`

**示例**：
- 如果模型设置了 `minTemperature=0.5, maxTemperature=1.5`
- 用户设置温度为 0.2，实际使用时会被限制为 0.5
- 用户设置温度为 1.8，实际使用时会被限制为 1.5

---

## 8. 技术支持

如果在前端适配过程中遇到问题，请：

1. 查看 [GitHub Issue #106](https://github.com/sdcb/chats/issues/106) 了解详细的设计背景
2. 参考后端代码中的类型定义和注释
3. 在 GitHub 仓库提交 Issue 或 PR

---

## 附录：完整类型定义

### AdminModelDto (完整)

```typescript
interface AdminModelDto {
  id: number;
  modelKeyId: number;
  name: string;
  deploymentName: string;
  order: number;
  enabled: boolean;
  inputTokenPrice1M: number;
  outputTokenPrice1M: number;
  
  // === 1.8.0 删除的字段 ===
  // modelReferenceId - 已删除
  // modelReferenceName - 已删除
  // modelReferenceShortName - 已删除
  
  // === 1.8.0 新增字段（全部必填）===
  allowSearch: boolean;
  allowVision: boolean;
  allowSystemPrompt: boolean;
  allowStreaming: boolean;
  allowCodeExecution: boolean;
  allowToolCall: boolean;
  thinkTagParserEnabled: boolean;
  
  minTemperature: number;
  maxTemperature: number;
  
  contextWindow: number;
  maxResponseTokens: number;
  
  reasoningEffortOptions: number[];
  supportedImageSizes: string[];
  
  apiType: number;
  useAsyncApi: boolean;
  useMaxCompletionTokens: boolean;
  isLegacy: boolean;
}
```
```

### UpdateModelRequest (完整)

```typescript
interface UpdateModelRequest {
  name: string;
  enabled: boolean;
  modelKeyId: number;
  deploymentName: string;
  inputTokenPrice1M: number;
  outputTokenPrice1M: number;
  
  // === 1.8.0 新增字段（全部必填）===
  allowSearch: boolean;
  allowVision: boolean;
  allowSystemPrompt: boolean;
  allowStreaming: boolean;
  allowCodeExecution: boolean;
  allowToolCall: boolean;
  thinkTagParserEnabled: boolean;
  
  minTemperature: number;
  maxTemperature: number;
  
  contextWindow: number;
  maxResponseTokens: number;
  
  reasoningEffortOptions: number[];
  supportedImageSizes: string[];
  
  apiType: number;
  useAsyncApi: boolean;
  useMaxCompletionTokens: boolean;
  isLegacy: boolean;
}
```

### PossibleModelDto (完整)

```typescript
interface PossibleModelDto {
  deploymentName: string;  // 必填，非空
  isExists: boolean;
}
```

### UserModelDto (完整)

```typescript
// 用户侧接口直接使用 AdminModelDto，包含所有字段
type UserModelDto = AdminModelDto;
```

---

**最后更新时间**: 2025-10-28
